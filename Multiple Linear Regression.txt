# Assignment 2: Multiple Regression – House Price Prediction

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score

# 1. Load dataset
df = pd.read_csv("house_price.csv")

print("Shape:", df.shape)
print(df.head())
print("\nMissing values:\n", df.isna().sum())

# Example selected features (change per your dataset)
# Rationale examples:
# - 'Sqft'       → size of house
# - 'Bedrooms'   → capacity
# - 'Bathrooms'  → comfort
# - 'Age'        → older houses cheaper
# - 'LocationScore' → neighborhood desirability
feature_cols = ["Sqft", "Bedrooms", "Bathrooms", "Age", "LocationScore"]

X = df[feature_cols]
y = df["Price"]

# Handle missing values (simple strategy)
X = X.fillna(X.median())
y = y.fillna(y.median())

# 2. Scaling (important when features have different units)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 3. Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# 4. Train model
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)

# 5. Coefficients & model equation
coefs = lin_reg.coef_
intercept = lin_reg.intercept_

print("\nIntercept:", intercept)
for name, c in zip(feature_cols, coefs):
    print(f"Coefficient for {name}: {c:.3f}")

# Interpretation: larger |coef| → stronger influence on price (after scaling).

# 6. Metrics
y_train_pred = lin_reg.predict(X_train)
y_test_pred = lin_reg.predict(X_test)

train_mse = mean_squared_error(y_train, y_train_pred)
test_mse = mean_squared_error(y_test, y_test_pred)
train_r2 = r2_score(y_train, y_train_pred)
test_r2 = r2_score(y_test, y_test_pred)

print(f"\nTrain MSE: {train_mse:.3f}, Train R^2: {train_r2:.3f}")
print(f"Test  MSE: {test_mse:.3f}, Test  R^2: {test_r2:.3f}")

# 7. Plot: Predicted vs Actual
plt.figure()
plt.scatter(y_test, y_test_pred)
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.title("Predicted vs Actual House Prices")
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()], "r--")  # perfect line
plt.show()

# In report: discuss which coefficients are largest, sign (+/-),
# and comment on under/overfitting based on metrics.
