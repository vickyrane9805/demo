# Assignment 3: Model Selection for Tabular Classification

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# 1. Load dataset
df = pd.read_csv("data.csv")   # generic tabular dataset
print(df.head())

X = df.drop("target", axis=1)
y = df["target"]

# 2. Preprocessing: fill missing values + scale
X = X.fillna(X.median())

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 3. 80/20 split, stratified (classification)
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

# Candidate models:
# - Logistic Regression (simple, linear)
# - Random Forest (non-linear, can capture interactions)

log_reg = LogisticRegression(max_iter=1000)
rf = RandomForestClassifier(
    n_estimators=200,
    max_depth=None,
    random_state=42
)

# 4. Train models
log_reg.fit(X_train, y_train)
rf.fit(X_train, y_train)

# 5. Evaluate
def evaluate_model(model, name):
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average="weighted")
    print(f"\n{name}:")
    print("Accuracy:", acc)
    print("F1-score (weighted):", f1)
    print("Classification report:\n", classification_report(y_test, y_pred))

evaluate_model(log_reg, "Logistic Regression")
evaluate_model(rf, "Random Forest")

# In report:
# - Explain why you might choose RF (better performance, handles non-linearity)
#   vs Logistic (simpler, more interpretable, less risk of overfitting).
# - Use metrics + complexity arguments to justify final choice.
